# ====================== å¥—ä»¶èˆ‡æ—¥æœŸè¨­å®š ======================
import pandas as pd
import glob
from tabulate import tabulate

start_date = pd.to_datetime("2024-05-01").date()
end_date   = pd.to_datetime("2025-05-01").date()
etf_list   = ["00733", "00850", "00692"]  # å¯è‡ªè¡Œæ–°å¢å…¶ä»– ETF ä»£ç¢¼

# ====================== åˆ†æ•¸èˆ‡åˆ†é¡å‡½å¼ ======================
def vix_signal(vix_close):
    if vix_close <= 15: return -1
    elif vix_close <= 19: return 0
    else: return 1

def classify_ptt_score(score):
    if pd.isna(score): return pd.NA
    if score > 0: return 1
    elif score < 0: return -1
    else: return 0

def get_sentiment(title):
    if pd.isna(title): return 0
    pos_score = sum(word in title for word in positive_keywords)
    neg_score = sum(word in title for word in negative_keywords)
    return pos_score - neg_score

def left_side_label(score):
    if score > 0: return -1
    elif score < 0: return 1
    else: return 0

def ETF_score(rate):
    if rate >= 0.10: return -1
    elif rate <= -0.10: return 1
    else: return 0

def classify_signal(score): 
    if pd.isna(score): return pd.NA
    if score >= 0.40: return "æ·±ç¶ ç‡ˆ"
    elif score >= 0.10: return "æ·ºç¶ ç‡ˆ"
    elif score >= -0.10: return "é»ƒç‡ˆ"
    elif score >= -0.50: return "æ·ºç´…ç‡ˆ"
    else: return "ç´…ç‡ˆ"
# ====================== æ ¸å¿ƒåˆ†æå‡½å¼ ======================
def analyze_etf(etf_code, vix_data, ptt_sentiment, positive_keywords, negative_keywords, megabank_df, cnyes_files):
    # è®€å– ETF æŠ˜æº¢åƒ¹
    etf_path = f"/content/MoneyDJ_ETF_PremiumDiscount_{etf_code}.csv"
    etf_df = pd.read_csv(etf_path, encoding="utf-8")
    etf_df["æ—¥æœŸ"] = pd.to_datetime(etf_df["äº¤æ˜“æ—¥æœŸ"]).dt.date
    etf_df = etf_df[(etf_df["æ—¥æœŸ"] >= start_date) & (etf_df["æ—¥æœŸ"] <= end_date)].copy()
    etf_df["æŠ˜æº¢åƒ¹åˆ©ç‡"] = etf_df["æŠ˜æº¢åƒ¹åˆ©ç‡(%)"].str.replace("%", "").astype(float)
    etf_df["æŠ˜æº¢åƒ¹åˆ†æ•¸"] = etf_df["æŠ˜æº¢åƒ¹åˆ©ç‡"].apply(ETF_score)

    # å…†è±æ–°è
    megabank = megabank_df.copy()
    megabank = megabank[(megabank["æ—¥æœŸ"] >= start_date) & (megabank["æ—¥æœŸ"] <= end_date)].copy()
    megabank["æ¯æ—¥åŸå§‹ç¸½åˆ†"] = megabank["æ¨™é¡Œ"].apply(get_sentiment)
    megabank = megabank.groupby("æ—¥æœŸ")["æ¯æ—¥åŸå§‹ç¸½åˆ†"].sum().reset_index()
    megabank["å·¦å´æƒ…ç·’åˆ†é¡"] = megabank["æ¯æ—¥åŸå§‹ç¸½åˆ†"].apply(left_side_label)
    megabank.rename(columns={
        "æ¯æ—¥åŸå§‹ç¸½åˆ†": "å…†è±_æ¯æ—¥åŸå§‹ç¸½åˆ†",
        "å·¦å´æƒ…ç·’åˆ†é¡": "å…†è±_å·¦å´æƒ…ç·’åˆ†é¡"
    }, inplace=True)

    # é‰…äº¨æ–°è
    cnyes_all = []
    for file in cnyes_files:
        df = pd.read_csv(file)
        df.columns = df.columns.str.strip()
        df = df.rename(columns={"æ™‚é–“": "date", "æ¨™é¡Œ": "title"})
        df["date"] = pd.to_datetime(df["date"]).dt.date
        df["sentiment"] = df["title"].apply(get_sentiment)
        cnyes_all.append(df)
    cnyes = pd.concat(cnyes_all)
    cnyes = cnyes.groupby("date")["sentiment"].sum().reset_index()
    cnyes.rename(columns={"date": "æ—¥æœŸ", "sentiment": "é‰…äº¨_æ¯æ—¥åŸå§‹ç¸½åˆ†"}, inplace=True)
    cnyes["é‰…äº¨_å·¦å´æƒ…ç·’åˆ†é¡"] = cnyes["é‰…äº¨_æ¯æ—¥åŸå§‹ç¸½åˆ†"].apply(left_side_label)
    cnyes = cnyes[(cnyes["æ—¥æœŸ"] >= start_date) & (cnyes["æ—¥æœŸ"] <= end_date)]

    # åˆä½µæ‰€æœ‰æŒ‡æ¨™
    df = pd.merge(megabank, cnyes, on="æ—¥æœŸ", how="outer")
    df = pd.merge(df, ptt_sentiment, on="æ—¥æœŸ", how="outer")
    df = pd.merge(df, vix_data, on="æ—¥æœŸ", how="left")
    df = pd.merge(df, etf_df[["æ—¥æœŸ", "æŠ˜æº¢åƒ¹åˆ©ç‡", "æŠ˜æº¢åƒ¹åˆ†æ•¸"]], on="æ—¥æœŸ", how="left")

    # è¨ˆç®—ç¸½åˆ†èˆ‡ç‡ˆè™Ÿ
    df["ç¸½åˆ†"] = (
        df["æŠ˜æº¢åƒ¹åˆ†æ•¸"].astype("float") * 0.5 +
        df["å…†è±_å·¦å´æƒ…ç·’åˆ†é¡"].astype("float") * 0.1 +
        df["é‰…äº¨_å·¦å´æƒ…ç·’åˆ†é¡"].astype("float") * 0.1 +
        df["PTT_è¼¿æƒ…åˆ†æ•¸"].astype("float") * 0.1 +
        df["ææ…Œåˆ†æ•¸"].astype("float") * 0.2
    )
    df["è©•åˆ†ç‡ˆè™Ÿ"] = df["ç¸½åˆ†"].apply(classify_signal)

    # è¼¸å‡º
    df.to_csv(f"/content/{etf_code}_sentiment_combined_with_score.csv", index=False, encoding="utf-8-sig")

    print(f"\nğŸ“ˆ ETF: {etf_code} åˆ†æå®Œæˆ")
    display_cols = ["æ—¥æœŸ", "å…†è±_æ¯æ—¥åŸå§‹ç¸½åˆ†", "å…†è±_å·¦å´æƒ…ç·’åˆ†é¡",
                    "é‰…äº¨_æ¯æ—¥åŸå§‹ç¸½åˆ†", "é‰…äº¨_å·¦å´æƒ…ç·’åˆ†é¡",
                    "PTT_æ¯æ—¥åˆ†æ•¸", "PTT_è¼¿æƒ…åˆ†æ•¸",
                    "æŠ˜æº¢åƒ¹åˆ©ç‡", "æŠ˜æº¢åƒ¹åˆ†æ•¸", "VIXæ”¶ç›¤åƒ¹", "ææ…Œåˆ†æ•¸", "ç¸½åˆ†", "è©•åˆ†ç‡ˆè™Ÿ"]
    print(tabulate(df[display_cols], headers="keys", tablefmt="grid", showindex=False))

# ====================== å‰ç½®è³‡æ–™è®€å– ======================
# VIX
vix_df = pd.read_csv("/content/vix_daily.csv")
vix_df["æ—¥æœŸ"] = pd.to_datetime(vix_df["Date"]).dt.date
vix_df = vix_df[(vix_df["æ—¥æœŸ"] >= start_date) & (vix_df["æ—¥æœŸ"] <= end_date)].copy()
vix_df["ææ…Œåˆ†æ•¸"] = vix_df["Close"].apply(vix_signal)
vix_data = vix_df[["æ—¥æœŸ", "Close", "ææ…Œåˆ†æ•¸"]].rename(columns={"Close": "VIXæ”¶ç›¤åƒ¹"})

# PTT è¼¿æƒ…
ptt_files = ["/content/ptt_stock/2024_scored.csv", "/content/ptt_stock/2025_scored.csv"]
ptt_all = []
for f in ptt_files:
    df = pd.read_csv(f)
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"]).dt.date
    df["æƒ…ç·’åˆ†æ•¸"] = pd.to_numeric(df["æƒ…ç·’åˆ†æ•¸"], errors="coerce")
    ptt_all.append(df)
ptt_df = pd.concat(ptt_all)
ptt_df = ptt_df[(ptt_df["æ—¥æœŸ"] >= start_date) & (ptt_df["æ—¥æœŸ"] <= end_date)]
ptt_grouped = ptt_df.groupby("æ—¥æœŸ")["æƒ…ç·’åˆ†æ•¸"].sum().reset_index()
ptt_grouped["PTT_æ¯æ—¥åˆ†æ•¸"] = ptt_grouped["æƒ…ç·’åˆ†æ•¸"]
ptt_grouped["PTT_è¼¿æƒ…åˆ†æ•¸"] = ptt_grouped["æƒ…ç·’åˆ†æ•¸"].apply(classify_ptt_score)
ptt_sentiment = ptt_grouped[["æ—¥æœŸ", "PTT_æ¯æ—¥åˆ†æ•¸", "PTT_è¼¿æƒ…åˆ†æ•¸"]]

# é—œéµè©
with open("/content/positive.txt", "r", encoding="utf-8") as f:
    positive_keywords = [line.strip() for line in f]
with open("/content/negative.txt", "r", encoding="utf-8") as f:
    negative_keywords = [line.strip() for line in f]

# å…†è±æ–°è
megabank_df = pd.read_csv("/content/megabank_news.csv")
megabank_df["æ—¥æœŸ"] = pd.to_datetime(megabank_df["æ—¥æœŸ"]).dt.date

# é‰…äº¨æ–°è
cnyes_files = glob.glob("/content/cnyes_headlines/cnyes_headlines_*.csv")

# ====================== åŸ·è¡Œå¤š ETF å›æ¸¬ ======================
for etf in etf_list:
    analyze_etf(etf, vix_data, ptt_sentiment, positive_keywords, negative_keywords, megabank_df, cnyes_files)
